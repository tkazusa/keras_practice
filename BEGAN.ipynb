{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chap12.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tkazusa/keras_practice/blob/master/BEGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zh769GwNMEVT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# BEGAN"
      ]
    },
    {
      "metadata": {
        "id": "FJAuAIVVMEVZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**共通モジュールの読み込み**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6EoENk-rlqG-",
        "outputId": "0492c79c-6897-453d-8015-b00afd1583da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.models import Sequential, Model\n",
        "from tensorflow.python.keras.layers import Conv2D, Conv2DTranspose, Activation, Flatten, Dense, UpSampling2D, Reshape, Lambda, Input\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.preprocessing.image import img_to_array, array_to_img"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "O0dQByEjMEWh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**画像を保存する関数**\n"
      ]
    },
    {
      "metadata": {
        "id": "QkCI9tLeMEWk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_imgs(path, imgs, rows, cols):\n",
        "    \"\"\"画像をタイル状にならべて保存する\n",
        "    \n",
        "    Arguments:\n",
        "        path (str): 保存先のファイルパス\n",
        "        imgs (np.array): 保存する画像のリスト\n",
        "        rows (int): タイルの縦のサイズ\n",
        "        cols (int): タイルの横のサイズ\n",
        "        \n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    base_width = imgs.shape[1]\n",
        "    base_height = imgs.shape[2]\n",
        "    channels = imgs.shape[3]\n",
        "    output_shape = (\n",
        "        base_height*rows,\n",
        "        base_width*cols,\n",
        "        channels\n",
        "    )\n",
        "    buffer = np.zeros(output_shape)\n",
        "    for row in range(rows):\n",
        "        for col in range(cols):\n",
        "            img = imgs[row*cols + col]\n",
        "            buffer[\n",
        "                row*base_height:(row + 1)*base_height,\n",
        "                col*base_width:(col + 1)*base_width\n",
        "            ] = img\n",
        "    array_to_img(buffer).save(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "PZhh5kkDFbXK"
      },
      "cell_type": "markdown",
      "source": [
        "**リスト12.1:画像データの読み込み**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_8jJdMsfmFQx",
        "outputId": "396afe0c-b66c-4559-ed55-c24ad3b316f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "DATA_DIR = 'data/chap12/'\n",
        "BATCH_SIZE = 16\n",
        "IMG_SHAPE = (64, 64, 3)\n",
        "\n",
        "data_gen = ImageDataGenerator(rescale=1/255.)\n",
        "train_data_generator = data_gen.flow_from_directory(\n",
        "    directory=DATA_DIR,\n",
        "    classes=['faces'],\n",
        "    class_mode=None,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=IMG_SHAPE[:2]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 19370 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "sHbFoscwFiPI"
      },
      "cell_type": "markdown",
      "source": [
        "**リスト 12.2:Encoderの定義**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LLFOMimZmKR_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_encoder(input_shape, z_size, n_filters, n_layers):\n",
        "    \"\"\"Encoderを構築する\n",
        "    \n",
        "    Arguments:\n",
        "        input_shape (int): 画像のshape\n",
        "        z_size (int): 特徴空間の次元数\n",
        "        n_filters (int): フィルタ数\n",
        "        \n",
        "    Returns:\n",
        "        model (Model): Encoderモデル \n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            n_filters,\n",
        "            3,\n",
        "            activation='elu',\n",
        "            input_shape=input_shape,\n",
        "            padding='same'\n",
        "        )\n",
        "    )\n",
        "    model.add(Conv2D(n_filters, 3, padding='same'))\n",
        "    for i in range(2, n_layers + 1):\n",
        "        model.add(\n",
        "            Conv2D(\n",
        "                i*n_filters,\n",
        "                3,\n",
        "                activation='elu',\n",
        "                padding='same'\n",
        "            )\n",
        "        )\n",
        "        model.add(\n",
        "                Conv2D(\n",
        "                i*n_filters,\n",
        "                3,\n",
        "                activation='elu',\n",
        "                strides=2,\n",
        "                padding='same'\n",
        "            )\n",
        "        )\n",
        "    model.add(Conv2D(n_layers*n_filters, 3, padding='same'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(z_size))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-7wXxnrXMEZv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**リスト12.3:Generator/Decoderの定義**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "elVBPfr-mONR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_decoder(output_shape, z_size, n_filters, n_layers):\n",
        "    \"\"\"Decoderを構築する\n",
        "    \n",
        "    Arguments:\n",
        "        output_shape (np.array): 画像のshape\n",
        "        z_size (int): 特徴空間の次元数\n",
        "        n_filters (int): フィルタ数\n",
        "        n_layers (int): レイヤー数数\n",
        "        \n",
        "    Returns:\n",
        "        model (Model): Decoderモデル \n",
        "    \"\"\"\n",
        "    # UpSampling2Dで何倍に拡大されるか\n",
        "    scale = 2**(n_layers - 1)\n",
        "    # 最初の畳み込み層の入力サイズをscaleから逆算\n",
        "    fc_shape = (\n",
        "        output_shape[0]//scale,\n",
        "        output_shape[1]//scale,\n",
        "        n_filters\n",
        "    )\n",
        "    # 全結合層で必要なサイズを逆算\n",
        "    fc_size = fc_shape[0]*fc_shape[1]*fc_shape[2]\n",
        "    \n",
        "    model = Sequential()\n",
        "    # 全結合層\n",
        "    model.add(Dense(fc_size, input_shape=(z_size,)))\n",
        "    model.add(Reshape(fc_shape))\n",
        "    \n",
        "    # 畳み込み層の繰り返し\n",
        "    for i in range(n_layers - 1):\n",
        "        model.add(\n",
        "            Conv2D(\n",
        "                n_filters,\n",
        "                3,\n",
        "                activation='elu',\n",
        "                padding='same'\n",
        "            )\n",
        "        )\n",
        "        model.add(\n",
        "            Conv2D(\n",
        "                n_filters,\n",
        "                3,\n",
        "                activation='elu',\n",
        "                padding='same'\n",
        "            )\n",
        "        )\n",
        "        model.add(UpSampling2D())\n",
        "        \n",
        "    # 最後の層はUpSampling2Dが不要\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            n_filters,\n",
        "            3,\n",
        "            activation='elu',\n",
        "            padding='same'\n",
        "        )\n",
        "    )\n",
        "    model.add(\n",
        "        Conv2D(\n",
        "            n_filters,\n",
        "            3,\n",
        "            activation='elu',\n",
        "            padding='same'\n",
        "        )\n",
        "    )\n",
        "    # 出力層で3チャンネルに\n",
        "    model.add(Conv2D(3, 3, padding='same'))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kGwqffNqMEZ7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**リスト12.4:Generatorの定義**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XoubtmhlmQh3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_generator(img_shape, z_size, n_filters, n_layers):\n",
        "    decoder = build_decoder(\n",
        "        img_shape, z_size, n_filters, n_layers\n",
        "    )\n",
        "    return decoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oBnNyi7SMEaP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**リスト12.5:Discriminatorの定義**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IHMwgdgYmSwO",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_discriminator(img_shape, z_size, n_filters, n_layers):\n",
        "    encoder = build_encoder(\n",
        "        img_shape, z_size, n_filters, n_layers\n",
        "    )\n",
        "    decoder = build_decoder(\n",
        "        img_shape, z_size, n_filters, n_layers\n",
        "    )\n",
        "    return keras.models.Sequential((encoder, decoder))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_cB7OpwMEac",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**リスト12.6:Discriminator学習用のネットワーク**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RbEZL3qtmU5a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_discriminator_trainer(discriminator):\n",
        "    img_shape = discriminator.input_shape[1:]\n",
        "    real_inputs = Input(img_shape)\n",
        "    fake_inputs = Input(img_shape)\n",
        "    real_outputs = discriminator(real_inputs)\n",
        "    fake_outputs = discriminator(fake_inputs)\n",
        "\n",
        "    return Model(\n",
        "        inputs=[real_inputs, fake_inputs],\n",
        "        outputs=[real_outputs, fake_outputs]\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iIahNkKOMEbD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**リスト12.7:ネットワークの構築**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KYSTnemdmXJL",
        "outputId": "50373191-3bb8-4ee3-b587-6dd979b042b2",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "cell_type": "code",
      "source": [
        "n_filters = 64  #  フィルタ数\n",
        "n_layers = 4 # レイヤー数\n",
        "z_size = 32  #  特徴空間の次元\n",
        "\n",
        "generator = build_generator(\n",
        "    IMG_SHAPE, z_size, n_filters, n_layers\n",
        ")\n",
        "discriminator = build_discriminator(\n",
        "    IMG_SHAPE, z_size, n_filters, n_layers\n",
        ")\n",
        "discriminator_trainer = build_discriminator_trainer(\n",
        "    discriminator\n",
        ")\n",
        "\n",
        "generator.summary()\n",
        "# discriminator.layers[1]が Decoder を表す\n",
        "discriminator.layers[1].summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 4096)              135168    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 64, 64, 3)         1731      \n",
            "=================================================================\n",
            "Total params: 432,323\n",
            "Trainable params: 432,323\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 4096)              135168    \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2 (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2 (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 64, 64, 3)         1731      \n",
            "=================================================================\n",
            "Total params: 432,323\n",
            "Trainable params: 432,323\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ug9WRtZqMEdT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**リスト12.8:損失関数の定義**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-i1VQ67WmeFz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.losses import mean_absolute_error\n",
        "\n",
        "\n",
        "def build_generator_loss(discriminator):\n",
        "    # discriminator を使って損失関数を定義\n",
        "    def loss(y_true, y_pred):\n",
        "        # y_true はダミー\n",
        "        reconst = discriminator(y_pred)\n",
        "        return mean_absolute_error(\n",
        "            reconst,\n",
        "            y_pred\n",
        "        )\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZhSDe2xLMEdh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**リスト12.9:generatorのコンパイル**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8xlrAPpOmhAf",
        "scrolled": false,
        "colab": {},
        "outputId": "9596bd9b-e91a-4be4-bd3e-c8de2f1908c4"
      },
      "cell_type": "code",
      "source": [
        "# 初期の学習率(Generator)\n",
        "g_lr = 0.0001\n",
        "\n",
        "generator_loss = build_generator_loss(discriminator)\n",
        "generator.compile(\n",
        "    loss=generator_loss,\n",
        "    optimizer=Adam(g_lr)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6snckm4uMEd0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**リスト12.10:discriminatorのコンパイル**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FcOeTJ1qmjub",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 初期の学習率(Discriminator)\n",
        "d_lr = 0.0001\n",
        "\n",
        "# k_varは数値(普通の変数)\n",
        "k_var = 0.0\n",
        "# k はKeras(TensorFlow)のVariable\n",
        "k = K.variable(k_var)\n",
        "discriminator_trainer.compile(\n",
        "    loss=[\n",
        "        mean_absolute_error,\n",
        "        mean_absolute_error\n",
        "    ],\n",
        "    loss_weights=[1., -k],\n",
        "    optimizer=Adam(d_lr)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PzLmIGUoMEeM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**リスト12.11:収束判定用の関数定義**"
      ]
    },
    {
      "metadata": {
        "id": "0az8B2XdMEeQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def measure(real_loss, fake_loss, gamma):\n",
        "    return real_loss + np.abs(gamma*real_loss - fake_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "y_e7mjM3F4Cg"
      },
      "cell_type": "markdown",
      "source": [
        "**リスト12.12*学習のコード**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ksY4_jqFml8y",
        "outputId": "669c8c2b-c62e-4b42-f52f-e0aa03548987",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "cell_type": "code",
      "source": [
        "# kの更新に利用するパラメータ\n",
        "GAMMA = 0.5\n",
        "LR_K = 0.001\n",
        "\n",
        "# 繰り返し数。100000〜1000000程度を指定\n",
        "TOTAL_STEPS = 100000\n",
        "\n",
        "# モデルや確認用の生成画像を保存するディレクトリ\n",
        "MODEL_SAVE_DIR = 'began/models'\n",
        "IMG_SAVE_DIR = 'began/imgs'\n",
        "# 確認用に5x5個の画像を生成する\n",
        "IMG_SAMPLE_SHAPE = (5, 5)\n",
        "N_IMG_SAMPLES = np.prod(IMG_SAMPLE_SHAPE)\n",
        "\n",
        "\n",
        "# 保存先がなければ作成\n",
        "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(IMG_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# サンプル画像用のランダムシード\n",
        "sample_seeds = np.random.uniform(\n",
        "    -1, 1, (N_IMG_SAMPLES, z_size)\n",
        ")\n",
        "\n",
        "history = []\n",
        "logs = []\n",
        "\n",
        "for step, batch in enumerate(train_data_generator):\n",
        "    # サンプル数がBATCH_SIZEに満たない場合はスキップ\n",
        "    # 全体の画像枚数がBATCH_SIZEの倍数出ない場合に発生\n",
        "    if len(batch) < BATCH_SIZE:\n",
        "        continue\n",
        "    \n",
        "    # 学習終了\n",
        "    if step > TOTAL_STEPS:\n",
        "        break\n",
        "\n",
        "    # ランダムな値を生成\n",
        "    z_g = np.random.uniform(\n",
        "        -1, 1, (BATCH_SIZE, z_size)\n",
        "    )\n",
        "    z_d = np.random.uniform(\n",
        "        -1, 1, (BATCH_SIZE, z_size)\n",
        "    )\n",
        "    \n",
        "    # 生成画像(discriminatorの学習に利用)\n",
        "    g_pred = generator.predict(z_d)\n",
        "    \n",
        "    # generatorを1ステップ分学習させる\n",
        "    generator.train_on_batch(z_g, batch)\n",
        "    # discriminatorを1ステップ分学習させる\n",
        "    _, real_loss, fake_loss = discriminator_trainer.train_on_batch(\n",
        "            [batch, g_pred],\n",
        "            [batch, g_pred]\n",
        "    )\n",
        "\n",
        "    # k を更新\n",
        "    k_var += LR_K*(GAMMA*real_loss - fake_loss)\n",
        "    K.set_value(k, k_var)\n",
        "    \n",
        "\n",
        "    # g_measure を計算するためにlossを保存\n",
        "    history.append({\n",
        "        'real_loss': real_loss,\n",
        "        'fake_loss': fake_loss\n",
        "    })\n",
        "\n",
        "    # 1000回に1度ログを表示\n",
        "    if step%1000 == 0:\n",
        "        # 過去1000回分の measure を平均\n",
        "        measurement = np.mean([\n",
        "            measure(\n",
        "                loss['real_loss'],\n",
        "                loss['fake_loss'],\n",
        "                GAMMA\n",
        "            )\n",
        "            for loss in history[-1000:]\n",
        "        ])\n",
        "        \n",
        "        logs.append({\n",
        "            'k': K.get_value(k),\n",
        "            'measure': measurement,\n",
        "            'real_loss': real_loss,\n",
        "            'fake_loss': fake_loss\n",
        "        })\n",
        "        print(logs[-1])\n",
        "\n",
        "        # 画像を保存  \n",
        "        img_path = '{}/generated_{}.png'.format(\n",
        "            IMG_SAVE_DIR,\n",
        "            step\n",
        "        )\n",
        "        save_imgs(\n",
        "            img_path,\n",
        "            generator.predict(sample_seeds),\n",
        "            rows=IMG_SAMPLE_SHAPE[0],\n",
        "            cols=IMG_SAMPLE_SHAPE[1]\n",
        "        )\n",
        "        # 最新のモデルを保存\n",
        "        generator.save('{}/generator_{}.hd5'.format(MODEL_SAVE_DIR, step))\n",
        "        discriminator.save('{}/discriminator_{}.hd5'.format(MODEL_SAVE_DIR, step))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'real_loss': 0.34090537, 'k': 0.000118427095, 'measure': 0.4593324661254883, 'fake_loss': 0.052025586}\n",
            "{'real_loss': 0.08183131, 'k': 0.03579138, 'measure': 0.1451206991095096, 'fake_loss': 0.025300503}\n",
            "{'real_loss': 0.08688027, 'k': 0.049796626, 'measure': 0.1114470398509875, 'fake_loss': 0.04925646}\n",
            "{'real_loss': 0.091323465, 'k': 0.055460535, 'measure': 0.1036260238327086, 'fake_loss': 0.051583435}\n",
            "{'real_loss': 0.08241842, 'k': 0.049101803, 'measure': 0.108314128652215, 'fake_loss': 0.051493365}\n",
            "{'real_loss': 0.08933789, 'k': 0.052159168, 'measure': 0.09520881587639451, 'fake_loss': 0.054427996}\n",
            "{'real_loss': 0.08997143, 'k': 0.061323058, 'measure': 0.09746647144481539, 'fake_loss': 0.027160294}\n",
            "{'real_loss': 0.080224335, 'k': 0.08799686, 'measure': 0.09880602482706308, 'fake_loss': 0.035442173}\n",
            "{'real_loss': 0.08644182, 'k': 0.09820156, 'measure': 0.0962351881787181, 'fake_loss': 0.036111902}\n",
            "{'real_loss': 0.08097395, 'k': 0.10616514, 'measure': 0.09429364058747888, 'fake_loss': 0.032288216}\n",
            "{'real_loss': 0.09083861, 'k': 0.112507254, 'measure': 0.09336474076285958, 'fake_loss': 0.038543526}\n",
            "{'real_loss': 0.08003414, 'k': 0.11847421, 'measure': 0.09205196098051965, 'fake_loss': 0.031737816}\n",
            "{'real_loss': 0.087775916, 'k': 0.12407474, 'measure': 0.09139789063297211, 'fake_loss': 0.049144007}\n",
            "{'real_loss': 0.08665567, 'k': 0.13017254, 'measure': 0.09231548514217139, 'fake_loss': 0.036393687}\n",
            "{'real_loss': 0.07613436, 'k': 0.13673025, 'measure': 0.09146976746991277, 'fake_loss': 0.041672446}\n",
            "{'real_loss': 0.07741143, 'k': 0.14165483, 'measure': 0.09109566341526806, 'fake_loss': 0.03696138}\n",
            "{'real_loss': 0.08934914, 'k': 0.14690055, 'measure': 0.09037486373260617, 'fake_loss': 0.027560381}\n",
            "{'real_loss': 0.08819784, 'k': 0.15180111, 'measure': 0.0900029734056443, 'fake_loss': 0.04523833}\n",
            "{'real_loss': 0.09010951, 'k': 0.15598202, 'measure': 0.0899109693877399, 'fake_loss': 0.04413008}\n",
            "{'real_loss': 0.08587758, 'k': 0.1588746, 'measure': 0.08892645746283233, 'fake_loss': 0.046370994}\n",
            "{'real_loss': 0.09086418, 'k': 0.16003771, 'measure': 0.09071555816009641, 'fake_loss': 0.039310798}\n",
            "{'real_loss': 0.07920203, 'k': 0.16044669, 'measure': 0.08906999968178571, 'fake_loss': 0.042274155}\n",
            "{'real_loss': 0.084600344, 'k': 0.16221508, 'measure': 0.08794039642065764, 'fake_loss': 0.034228787}\n",
            "{'real_loss': 0.0830298, 'k': 0.16020721, 'measure': 0.08943608290329576, 'fake_loss': 0.04923513}\n",
            "{'real_loss': 0.07541449, 'k': 0.1512112, 'measure': 0.09417435539327562, 'fake_loss': 0.04980162}\n",
            "{'real_loss': 0.080125675, 'k': 0.14337818, 'measure': 0.09216136657819152, 'fake_loss': 0.042203903}\n",
            "{'real_loss': 0.0818099, 'k': 0.13599217, 'measure': 0.0910060108564794, 'fake_loss': 0.04861114}\n",
            "{'real_loss': 0.075435326, 'k': 0.12876476, 'measure': 0.09025824445858598, 'fake_loss': 0.04048593}\n",
            "{'real_loss': 0.082374685, 'k': 0.122939505, 'measure': 0.08846533678099514, 'fake_loss': 0.044267006}\n",
            "{'real_loss': 0.08430277, 'k': 0.1172194, 'measure': 0.08816240939870476, 'fake_loss': 0.04128721}\n",
            "{'real_loss': 0.081202775, 'k': 0.11233344, 'measure': 0.08699665830656886, 'fake_loss': 0.046892717}\n",
            "{'real_loss': 0.08548428, 'k': 0.107305035, 'measure': 0.0877529560662806, 'fake_loss': 0.053659502}\n",
            "{'real_loss': 0.08461666, 'k': 0.1034115, 'measure': 0.08573677456378936, 'fake_loss': 0.04183558}\n",
            "{'real_loss': 0.08073716, 'k': 0.09943728, 'measure': 0.0857083757519722, 'fake_loss': 0.05261141}\n",
            "{'real_loss': 0.08533743, 'k': 0.09525692, 'measure': 0.08585364986211061, 'fake_loss': 0.04731365}\n",
            "{'real_loss': 0.07515584, 'k': 0.09153719, 'measure': 0.08486134855076671, 'fake_loss': 0.04524283}\n",
            "{'real_loss': 0.075938925, 'k': 0.08855422, 'measure': 0.08364106548577548, 'fake_loss': 0.055075236}\n",
            "{'real_loss': 0.07662517, 'k': 0.08495132, 'measure': 0.08444413441419601, 'fake_loss': 0.04410427}\n",
            "{'real_loss': 0.07176988, 'k': 0.082040064, 'measure': 0.0837937298156321, 'fake_loss': 0.040853262}\n",
            "{'real_loss': 0.07331516, 'k': 0.08001076, 'measure': 0.0831639096867293, 'fake_loss': 0.040533543}\n",
            "{'real_loss': 0.0713865, 'k': 0.07760634, 'measure': 0.08319059565290808, 'fake_loss': 0.041902587}\n",
            "{'real_loss': 0.078128174, 'k': 0.076130114, 'measure': 0.08239969856478274, 'fake_loss': 0.036074303}\n",
            "{'real_loss': 0.07579709, 'k': 0.07436853, 'measure': 0.08235626750066877, 'fake_loss': 0.055115968}\n",
            "{'real_loss': 0.07846805, 'k': 0.07247866, 'measure': 0.08227690635621547, 'fake_loss': 0.043360755}\n",
            "{'real_loss': 0.075918466, 'k': 0.07164813, 'measure': 0.0814995639603585, 'fake_loss': 0.03126003}\n",
            "{'real_loss': 0.07588938, 'k': 0.070843615, 'measure': 0.08164478017762303, 'fake_loss': 0.036459427}\n",
            "{'real_loss': 0.07783525, 'k': 0.06914285, 'measure': 0.0816069760248065, 'fake_loss': 0.042164657}\n",
            "{'real_loss': 0.07804671, 'k': 0.06839775, 'measure': 0.08099969259090721, 'fake_loss': 0.03577278}\n",
            "{'real_loss': 0.07907237, 'k': 0.067322716, 'measure': 0.08106995446979999, 'fake_loss': 0.03575533}\n",
            "{'real_loss': 0.06452426, 'k': 0.066076286, 'measure': 0.0813209171295166, 'fake_loss': 0.032046232}\n",
            "{'real_loss': 0.07954387, 'k': 0.0657003, 'measure': 0.08022673683241009, 'fake_loss': 0.046772227}\n",
            "{'real_loss': 0.07866966, 'k': 0.061570752, 'measure': 0.08363705188594758, 'fake_loss': 0.05270613}\n",
            "{'real_loss': 0.06391063, 'k': 0.061946306, 'measure': 0.07958429759554565, 'fake_loss': 0.03861221}\n",
            "{'real_loss': 0.08105693, 'k': 0.06279907, 'measure': 0.07933405868336559, 'fake_loss': 0.035475094}\n",
            "{'real_loss': 0.078753375, 'k': 0.06258982, 'measure': 0.07975259684398771, 'fake_loss': 0.03529446}\n",
            "{'real_loss': 0.086029805, 'k': 0.06196863, 'measure': 0.0799877812359482, 'fake_loss': 0.040925846}\n",
            "{'real_loss': 0.07415127, 'k': 0.061750636, 'measure': 0.07944634489901364, 'fake_loss': 0.042930525}\n",
            "{'real_loss': 0.07229844, 'k': 0.06106221, 'measure': 0.07910216731391848, 'fake_loss': 0.037804984}\n",
            "{'real_loss': 0.076589346, 'k': 0.06084246, 'measure': 0.07887642933614553, 'fake_loss': 0.031196646}\n",
            "{'real_loss': 0.07136485, 'k': 0.060081176, 'measure': 0.07949724413640798, 'fake_loss': 0.035080872}\n",
            "{'real_loss': 0.06009601, 'k': 0.05981635, 'measure': 0.07913847254961728, 'fake_loss': 0.041328996}\n",
            "{'real_loss': 0.07764681, 'k': 0.060081415, 'measure': 0.07859340817481279, 'fake_loss': 0.03389094}\n",
            "{'real_loss': 0.07680375, 'k': 0.05979971, 'measure': 0.07878309943713248, 'fake_loss': 0.03811784}\n",
            "{'real_loss': 0.07162875, 'k': 0.059321254, 'measure': 0.07831286149285734, 'fake_loss': 0.036748808}\n",
            "{'real_loss': 0.079677954, 'k': 0.059762534, 'measure': 0.07796013374440372, 'fake_loss': 0.043082364}\n",
            "{'real_loss': 0.08457188, 'k': 0.05958025, 'measure': 0.07818122506327928, 'fake_loss': 0.03729785}\n",
            "{'real_loss': 0.06922272, 'k': 0.05886076, 'measure': 0.0782195534016937, 'fake_loss': 0.035617046}\n",
            "{'real_loss': 0.06120216, 'k': 0.058420144, 'measure': 0.0775769279524684, 'fake_loss': 0.03876651}\n",
            "{'real_loss': 0.07814402, 'k': 0.058305483, 'measure': 0.07775531044788658, 'fake_loss': 0.04329418}\n",
            "{'real_loss': 0.0719288, 'k': 0.05802201, 'measure': 0.07767592276446521, 'fake_loss': 0.035754345}\n",
            "{'real_loss': 0.06689976, 'k': 0.05719955, 'measure': 0.07763125194236636, 'fake_loss': 0.039039277}\n",
            "{'real_loss': 0.07293797, 'k': 0.057017483, 'measure': 0.07703643237426877, 'fake_loss': 0.037013497}\n",
            "{'real_loss': 0.067625195, 'k': 0.05637658, 'measure': 0.07773053270950914, 'fake_loss': 0.03501668}\n",
            "{'real_loss': 0.074832946, 'k': 0.05654566, 'measure': 0.07670761133916676, 'fake_loss': 0.045062922}\n",
            "{'real_loss': 0.08418034, 'k': 0.05596951, 'measure': 0.07740153258666396, 'fake_loss': 0.037733514}\n",
            "{'real_loss': 0.0645031, 'k': 0.056001004, 'measure': 0.07645252075046301, 'fake_loss': 0.032959238}\n",
            "{'real_loss': 0.07479296, 'k': 0.055971652, 'measure': 0.07643776120431721, 'fake_loss': 0.033990826}\n",
            "{'real_loss': 0.07414876, 'k': 0.055821333, 'measure': 0.07653749777376652, 'fake_loss': 0.039912216}\n",
            "{'real_loss': 0.07083951, 'k': 0.0552429, 'measure': 0.0766008857768029, 'fake_loss': 0.042215995}\n",
            "{'real_loss': 0.07224442, 'k': 0.055279266, 'measure': 0.0761303738988936, 'fake_loss': 0.031466372}\n",
            "{'real_loss': 0.08281885, 'k': 0.054374475, 'measure': 0.07644737895205617, 'fake_loss': 0.0489516}\n",
            "{'real_loss': 0.08062533, 'k': 0.054378513, 'measure': 0.07588920643180609, 'fake_loss': 0.034711443}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "{'real_loss': 0.07457939, 'k': 0.054366313, 'measure': 0.0757672393284738, 'fake_loss': 0.03487847}\n",
            "{'real_loss': 0.08018494, 'k': 0.05386619, 'measure': 0.07610669267363847, 'fake_loss': 0.036230564}\n",
            "{'real_loss': 0.06778379, 'k': 0.053375855, 'measure': 0.07614306828007102, 'fake_loss': 0.03420984}\n",
            "{'real_loss': 0.073367886, 'k': 0.053246904, 'measure': 0.07551862653717399, 'fake_loss': 0.036833167}\n",
            "{'real_loss': 0.07031652, 'k': 0.05231414, 'measure': 0.0761380194183439, 'fake_loss': 0.034510553}\n",
            "{'real_loss': 0.07142706, 'k': 0.0521284, 'measure': 0.07538464302197098, 'fake_loss': 0.03914842}\n",
            "{'real_loss': 0.08296743, 'k': 0.052254938, 'measure': 0.0750698865260929, 'fake_loss': 0.03415202}\n",
            "{'real_loss': 0.07058626, 'k': 0.05228032, 'measure': 0.07513997263275086, 'fake_loss': 0.03698089}\n",
            "{'real_loss': 0.0711849, 'k': 0.051456176, 'measure': 0.0753285081665963, 'fake_loss': 0.033147514}\n",
            "{'real_loss': 0.08089878, 'k': 0.04776503, 'measure': 0.07753670414350927, 'fake_loss': 0.037271418}\n",
            "{'real_loss': 0.07828368, 'k': 0.047561597, 'measure': 0.0746476292796433, 'fake_loss': 0.039853744}\n",
            "{'real_loss': 0.075813666, 'k': 0.047677465, 'measure': 0.07475587227009237, 'fake_loss': 0.03591407}\n",
            "{'real_loss': 0.08380462, 'k': 0.047907285, 'measure': 0.07450694610178471, 'fake_loss': 0.03571652}\n",
            "{'real_loss': 0.066700235, 'k': 0.048081186, 'measure': 0.07474565043859184, 'fake_loss': 0.034438506}\n",
            "{'real_loss': 0.06256552, 'k': 0.04786755, 'measure': 0.07462605653516949, 'fake_loss': 0.03705504}\n",
            "{'real_loss': 0.07622569, 'k': 0.04819676, 'measure': 0.0741917349845171, 'fake_loss': 0.038078617}\n",
            "{'real_loss': 0.06904526, 'k': 0.047651425, 'measure': 0.07407027686759829, 'fake_loss': 0.037918426}\n",
            "{'real_loss': 0.0726022, 'k': 0.04804468, 'measure': 0.07368206452764571, 'fake_loss': 0.032724462}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Za2tVwTMEfP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}